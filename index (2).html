<!DOCTYPE html>
<html lang="pt-BR">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Ecossistema LLM - Diagrama Interativo</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: linear-gradient(135deg, #0F172A 0%, #1E293B 100%);
            min-height: 100vh;
            color: #E2E8F0;
            overflow-x: hidden;
        }

        .header {
            background: rgba(15, 23, 42, 0.9);
            backdrop-filter: blur(10px);
            padding: 20px;
            border-bottom: 1px solid rgba(148, 163, 184, 0.1);
            position: fixed;
            width: 100%;
            top: 0;
            z-index: 1000;
        }

        .header h1 {
            text-align: center;
            font-size: 24px;
            background: linear-gradient(135deg, #60A5FA 0%, #A78BFA 100%);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            margin-bottom: 10px;
        }

        .controls {
            display: flex;
            justify-content: center;
            gap: 10px;
            flex-wrap: wrap;
            margin-bottom: 10px;
        }

        .btn {
            padding: 8px 16px;
            background: linear-gradient(135deg, #3B82F6 0%, #8B5CF6 100%);
            border: none;
            border-radius: 8px;
            color: white;
            cursor: pointer;
            font-size: 14px;
            transition: all 0.3s ease;
            font-weight: 500;
        }

        .btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 10px 20px rgba(59, 130, 246, 0.3);
        }

        .btn.active {
            background: linear-gradient(135deg, #10B981 0%, #059669 100%);
        }

        .search-input {
            width: 260px;
            padding: 8px 12px;
            border-radius: 8px;
            border: 1px solid rgba(148, 163, 184, 0.2);
            background: rgba(30, 41, 59, 0.7);
            color: #E2E8F0;
            outline: none;
            font-size: 14px;
        }

        .search-input::placeholder {
            color: #94A3B8;
        }

        .main-container {
            margin-top: 140px;
            padding: 20px;
            display: flex;
            gap: 20px;
            max-width: 1600px;
            margin-left: auto;
            margin-right: auto;
        }

        .canvas-container {
            flex: 1;
            background: rgba(30, 41, 59, 0.5);
            border-radius: 16px;
            padding: 20px;
            box-shadow: 0 20px 40px rgba(0, 0, 0, 0.3);
            border: 1px solid rgba(148, 163, 184, 0.1);
            position: relative;
        }

        #mainCanvas {
            background: radial-gradient(circle at center, #1E293B 0%, #0F172A 100%);
            border-radius: 12px;
            cursor: grab;
            width: 100%;
            display: block;
        }

        #mainCanvas:active {
            cursor: grabbing;
        }

        .info-panel {
            width: 420px;
            background: rgba(30, 41, 59, 0.5);
            border-radius: 16px;
            padding: 20px;
            box-shadow: 0 20px 40px rgba(0, 0, 0, 0.3);
            border: 1px solid rgba(148, 163, 184, 0.1);
            max-height: 600px;
            overflow-y: auto;
        }

        .info-panel h2 {
            font-size: 20px;
            margin-bottom: 15px;
            background: linear-gradient(135deg, #60A5FA 0%, #A78BFA 100%);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
        }

        .info-content {
            background: rgba(15, 23, 42, 0.5);
            padding: 15px;
            border-radius: 12px;
            border: 1px solid rgba(148, 163, 184, 0.1);
            margin-bottom: 15px;
        }

        .info-content h3 {
            color: #60A5FA;
            margin-bottom: 10px;
            font-size: 16px;
        }

        .info-content p {
            color: #CBD5E1;
            line-height: 1.6;
            font-size: 14px;
        }

        .info-content ul {
            margin-left: 20px;
            margin-top: 10px;
        }

        .info-content li {
            color: #94A3B8;
            margin-bottom: 5px;
            font-size: 14px;
        }

        .legend {
            display: flex;
            gap: 20px;
            margin-top: 15px;
            flex-wrap: wrap;
        }

        .legend-item {
            display: flex;
            align-items: center;
            gap: 8px;
        }

        .legend-color {
            width: 20px;
            height: 20px;
            border-radius: 4px;
        }

        .zoom-controls {
            position: absolute;
            bottom: 20px;
            right: 20px;
            display: flex;
            flex-direction: column;
            gap: 5px;
        }

        .zoom-btn {
            width: 40px;
            height: 40px;
            border-radius: 8px;
            background: rgba(30, 41, 59, 0.9);
            border: 1px solid rgba(148, 163, 184, 0.2);
            color: #CBD5E1;
            cursor: pointer;
            font-size: 20px;
            display: flex;
            align-items: center;
            justify-content: center;
            transition: all 0.3s ease;
        }

        .zoom-btn:hover {
            background: rgba(59, 130, 246, 0.2);
            border-color: #3B82F6;
        }

        .tooltip {
            position: absolute;
            background: rgba(15, 23, 42, 0.95);
            padding: 10px;
            border-radius: 8px;
            border: 1px solid rgba(148, 163, 184, 0.2);
            pointer-events: none;
            z-index: 1000;
            max-width: 280px;
            font-size: 13px;
            box-shadow: 0 10px 20px rgba(0, 0, 0, 0.3);
            display: none;
        }

        ::-webkit-scrollbar {
            width: 8px;
        }

        ::-webkit-scrollbar-track {
            background: rgba(30, 41, 59, 0.3);
            border-radius: 4px;
        }

        ::-webkit-scrollbar-thumb {
            background: linear-gradient(135deg, #3B82F6 0%, #8B5CF6 100%);
            border-radius: 4px;
        }

        @media (max-width: 1200px) {
            .main-container {
                flex-direction: column;
            }
            .info-panel {
                width: 100%;
                max-height: none;
            }
        }
    </style>
</head>
<body>
    <div class="header">
        <h1>üß† Ecossistema de Grandes Modelos de Linguagem (LLMs)</h1>
        <div class="controls">
            <!-- search bar -->
            <input id="searchInput" class="search-input" type="text" placeholder="Pesquisar n√≥s..." oninput="filterNodes(this.value)" />
        </div>
        <div class="controls">
            <button class="btn active" onclick="showView('overview', this)">Vis√£o Geral</button>
            <button class="btn" onclick="showView('models', this)">Modelos</button>
            <button class="btn" onclick="showView('training', this)">Treinamento</button>
            <button class="btn" onclick="showView('inference', this)">Infer√™ncia</button>
            <button class="btn" onclick="showView('rag', this)">RAG</button>
            <button class="btn" onclick="showView('prompting', this)">Prompting</button>
            <button class="btn" onclick="animateFlow()">üé¨ Animar Fluxo</button>
        </div>
    </div>

    <div class="main-container">
        <div class="canvas-container">
            <canvas id="mainCanvas"></canvas>
            <div class="zoom-controls">
                <button class="zoom-btn" onclick="zoomIn()">+</button>
                <button class="zoom-btn" onclick="zoomOut()">‚àí</button>
                <button class="zoom-btn" onclick="resetZoom()">‚ü≤</button>
            </div>
            <div class="legend">
                <div class="legend-item">
                    <div class="legend-color" style="background: linear-gradient(135deg, #3B82F6, #8B5CF6)"></div>
                    <span>Modelos Base</span>
                </div>
                <div class="legend-item">
                    <div class="legend-color" style="background: linear-gradient(135deg, #10B981, #059669)"></div>
                    <span>Treinamento</span>
                </div>
                <div class="legend-item">
                    <div class="legend-color" style="background: linear-gradient(135deg, #F59E0B, #DC2626)"></div>
                    <span>Infer√™ncia</span>
                </div>
                <div class="legend-item">
                    <div class="legend-color" style="background: linear-gradient(135deg, #EC4899, #8B5CF6)"></div>
                    <span>RAG/Retrieval</span>
                </div>
            </div>
        </div>
        <div class="info-panel">
            <h2>üìä Informa√ß√µes Detalhadas</h2>
            <div id="infoContent">
                <div class="info-content">
                    <h3>Bem-vindo ao Ecossistema LLM</h3>
                    <p>Este diagrama interativo apresenta os principais componentes e fluxos dos Grandes Modelos de Linguagem. Clique nos elementos para explorar cada conceito em detalhes.</p>
                    <ul>
                        <li>üñ±Ô∏è Clique nos n√≥s para ver detalhes</li>
                        <li>üîç Use zoom para navegar</li>
                        <li>üéØ Arraste para mover o diagrama</li>
                        <li>üìö Explore diferentes visualiza√ß√µes</li>
                    </ul>
                </div>
            </div>
        </div>
    </div>
    <div class="tooltip" id="tooltip"></div>

    <script>
        const canvas = document.getElementById('mainCanvas');
        const ctx = canvas.getContext('2d');
        const tooltip = document.getElementById('tooltip');

        // Canvas setup
        let scale = 1;
        let offsetX = 0;
        let offsetY = 0;
        let isDragging = false;
        let dragStartX = 0;
        let dragStartY = 0;
        let currentView = 'overview';
        let animationFrame = null;
        let particles = [];
        let searchQuery = '';

        // Node class
        class Node {
            constructor(x, y, label, type, description, details) {
                this.x = x;
                this.y = y;
                this.label = label;
                this.type = type;
                this.description = description;
                this.details = details || {};
                this.radius = 40;
                this.hover = false;
                this.selected = false;
                this.highlight = false;
                this.pulsePhase = Math.random() * Math.PI * 2;
                this.connections = [];
            }
            draw() {
                ctx.save();
                ctx.translate(this.x + offsetX, this.y + offsetY);
                ctx.scale(scale, scale);
                // Adjust opacity if filtered
                const dimFactor = (searchQuery && !this.highlight) ? 0.2 : 1;
                // Glow effect
                if (this.hover || this.selected) {
                    const gradient = ctx.createRadialGradient(0, 0, 0, 0, 0, this.radius * 2);
                    gradient.addColorStop(0, this.getColor(0.3 * dimFactor));
                    gradient.addColorStop(1, 'transparent');
                    ctx.fillStyle = gradient;
                    ctx.beginPath();
                    ctx.arc(0, 0, this.radius * 2, 0, Math.PI * 2);
                    ctx.fill();
                }
                // Pulse animation
                const pulse = Math.sin(Date.now() / 1000 + this.pulsePhase) * 0.1 + 1;
                const currentRadius = this.hover ? this.radius * 1.1 * pulse : this.radius;
                // Main circle
                const gradient2 = ctx.createRadialGradient(0, 0, 0, 0, 0, currentRadius);
                gradient2.addColorStop(0, this.getColor(0.9 * dimFactor));
                gradient2.addColorStop(1, this.getColor(0.6 * dimFactor));
                ctx.fillStyle = gradient2;
                ctx.beginPath();
                ctx.arc(0, 0, currentRadius, 0, Math.PI * 2);
                ctx.fill();
                // Border
                ctx.strokeStyle = this.getColor(1 * dimFactor);
                ctx.lineWidth = this.selected ? 3 : 2;
                ctx.stroke();
                // Icon
                ctx.fillStyle = `rgba(255,255,255,${dimFactor})`;
                ctx.font = 'bold 20px Arial';
                ctx.textAlign = 'center';
                ctx.textBaseline = 'middle';
                ctx.fillText(this.getIcon(), 0, -5);
                // Label
                ctx.font = '12px Inter, sans-serif';
                ctx.fillText(this.label, 0, currentRadius + 20);
                ctx.restore();
            }
            getColor(opacity) {
                const colors = {
                    model: `rgba(59, 130, 246, ${opacity})`,
                    training: `rgba(16, 185, 129, ${opacity})`,
                    inference: `rgba(245, 158, 11, ${opacity})`,
                    rag: `rgba(236, 72, 153, ${opacity})`,
                    prompt: `rgba(139, 92, 246, ${opacity})`,
                    data: `rgba(6, 182, 212, ${opacity})`
                };
                return colors[this.type] || `rgba(148, 163, 184, ${opacity})`;
            }
            getIcon() {
                const icons = {
                    model: 'ü§ñ',
                    training: 'üéì',
                    inference: '‚ö°',
                    rag: 'üîç',
                    prompt: 'üí≠',
                    data: 'üìä'
                };
                return icons[this.type] || 'üì¶';
            }
            isHovered(mx, my) {
                const dx = (mx - offsetX) / scale - this.x;
                const dy = (my - offsetY) / scale - this.y;
                return Math.sqrt(dx * dx + dy * dy) < this.radius;
            }
        }
        // Connection class
        class Connection {
            constructor(from, to, label, type = 'normal') {
                this.from = from;
                this.to = to;
                this.label = label;
                this.type = type;
                this.animationOffset = 0;
            }
            draw() {
                ctx.save();
                ctx.translate(offsetX, offsetY);
                ctx.scale(scale, scale);
                const dx = this.to.x - this.from.x;
                const dy = this.to.y - this.from.y;
                const distance = Math.sqrt(dx * dx + dy * dy);
                const unitX = dx / distance;
                const unitY = dy / distance;
                const startX = this.from.x + unitX * this.from.radius;
                const startY = this.from.y + unitY * this.from.radius;
                const endX = this.to.x - unitX * this.to.radius;
                const endY = this.to.y - unitY * this.to.radius;
                ctx.beginPath();
                ctx.moveTo(startX, startY);
                if (this.type === 'curved') {
                    const cp1x = startX + (endX - startX) * 0.3;
                    const cp1y = startY - 50;
                    const cp2x = startX + (endX - startX) * 0.7;
                    const cp2y = endY - 50;
                    ctx.bezierCurveTo(cp1x, cp1y, cp2x, cp2y, endX, endY);
                } else {
                    ctx.lineTo(endX, endY);
                }
                ctx.strokeStyle = 'rgba(148, 163, 184, 0.3)';
                ctx.lineWidth = 2;
                ctx.stroke();
                if (this.type === 'animated') {
                    ctx.setLineDash([5, 10]);
                    ctx.lineDashOffset = -this.animationOffset;
                    ctx.strokeStyle = 'rgba(59, 130, 246, 0.6)';
                    ctx.stroke();
                    ctx.setLineDash([]);
                    this.animationOffset += 0.5;
                }
                // Arrow
                const arrowSize = 10;
                const angle = Math.atan2(dy, dx);
                ctx.fillStyle = 'rgba(148, 163, 184, 0.5)';
                ctx.beginPath();
                ctx.moveTo(endX, endY);
                ctx.lineTo(
                    endX - arrowSize * Math.cos(angle - Math.PI / 6),
                    endY - arrowSize * Math.sin(angle - Math.PI / 6)
                );
                ctx.lineTo(
                    endX - arrowSize * Math.cos(angle + Math.PI / 6),
                    endY - arrowSize * Math.sin(angle + Math.PI / 6)
                );
                ctx.closePath();
                ctx.fill();
                // Label
                if (this.label) {
                    const midX = (startX + endX) / 2;
                    const midY = (startY + endY) / 2;
                    ctx.fillStyle = 'rgba(203, 213, 225, 0.8)';
                    ctx.font = '11px Inter, sans-serif';
                    ctx.textAlign = 'center';
                    ctx.fillText(this.label, midX, midY - 10);
                }
                ctx.restore();
            }
        }
        // Particle class for animations
        class Particle {
            constructor(x, y, targetX, targetY, color) {
                this.x = x;
                this.y = y;
                this.targetX = targetX;
                this.targetY = targetY;
                this.color = color;
                this.speed = 2;
                this.size = 3;
                this.trail = [];
                this.maxTrailLength = 20;
            }
            update() {
                const dx = this.targetX - this.x;
                const dy = this.targetY - this.y;
                const distance = Math.sqrt(dx * dx + dy * dy);
                if (distance > 5) {
                    this.trail.push({x: this.x, y: this.y});
                    if (this.trail.length > this.maxTrailLength) {
                        this.trail.shift();
                    }
                    this.x += (dx / distance) * this.speed;
                    this.y += (dy / distance) * this.speed;
                    return true;
                }
                return false;
            }
            draw() {
                ctx.save();
                ctx.translate(offsetX, offsetY);
                ctx.scale(scale, scale);
                this.trail.forEach((point, index) => {
                    ctx.fillStyle = this.color.replace('1)', `${0.5 * index / this.trail.length})`);
                    ctx.beginPath();
                    ctx.arc(point.x, point.y, this.size * (index / this.trail.length), 0, Math.PI * 2);
                    ctx.fill();
                });
                const grad = ctx.createRadialGradient(this.x, this.y, 0, this.x, this.y, this.size * 2);
                grad.addColorStop(0, this.color);
                grad.addColorStop(1, 'transparent');
                ctx.fillStyle = grad;
                ctx.beginPath();
                ctx.arc(this.x, this.y, this.size * 2, 0, Math.PI * 2);
                ctx.fill();
                ctx.restore();
            }
        }
        // Initialize nodes and connections
        let nodes = [];
        let connections = [];
        function initializeNodes() {
            nodes = [];
            connections = [];
            if (currentView === 'overview') {
                // Models
                nodes.push(new Node(200, 150, 'GPT-4', 'model', 'Modelo da OpenAI', {
                    Empresa: 'OpenAI',
                    Par√¢metros: '1.76T',
                    Contexto: '128k tokens',
                    Multimodal: 'Texto, Imagem, C√≥digo'
                }));
                nodes.push(new Node(400, 150, 'Claude 3', 'model', 'Modelo da Anthropic', {
                    Empresa: 'Anthropic',
                    Vers√µes: 'Haiku, Sonnet, Opus',
                    Contexto: '200k tokens',
                    Foco: 'Seguran√ßa e alinhamento'
                }));
                nodes.push(new Node(600, 150, 'Gemini', 'model', 'Modelo do Google', {
                    Empresa: 'Google DeepMind',
                    Multimodal: 'Texto, Imagem, √Åudio, V√≠deo',
                    Contexto: '1M tokens (Pro)',
                    Integra√ß√£o: 'Vertex AI'
                }));
                nodes.push(new Node(800, 150, 'Llama', 'model', 'Modelo da Meta', {
                    Empresa: 'Meta',
                    Vers√µes: 'Llama 2, Llama 3',
                    C√≥digo: 'Aberto',
                    Par√¢metros: '8B, 70B, 405B'
                }));
                // Training
                nodes.push(new Node(300, 300, 'RLHF', 'training', 'Refor√ßo com Feedback Humano', {
                    "Etapas": '1. Pr√©‚Äëtreinar; 2. Treinar modelo de recompensa com avalia√ß√µes humanas; 3. Ajustar com algoritmos de RL„Äê468964752385088‚Ä†L60-L120„Äë.',
                    "Objetivo": 'Alinhar a gera√ß√£o do modelo com prefer√™ncias humanas e garantir respostas seguras.',
                    "Funcionamento": 'Humanos compararam respostas; o modelo aprende a maximizar uma fun√ß√£o de recompensa; usa PPO ou t√©cnicas semelhantes.',
                    "Complexidade": 'Treinamento custoso, requer dados de prefer√™ncia e ajuste delicado.',
                    "Uso": 'Adotado em modelos comerciais como ChatGPT e Claude para melhorar seguran√ßa e utilidade.'
                }));
                nodes.push(new Node(500, 300, 'Fine‚Äëtuning', 'training', 'Ajuste fino de modelos', {
                    "T√©cnicas": 'LoRA, QLoRA, Adapters, Prefix‚ÄëTuning, PEFT.',
                    "Vantagens": 'Atualiza apenas partes do modelo, reduzindo custo de mem√≥ria e computa√ß√£o.',
                    "Aplica√ß√£o": 'Adaptar modelos fundacionais a dom√≠nios espec√≠ficos (jur√≠dico, m√©dico) sem treinar do zero.',
                    "Observa√ß√£o": 'Exige curadoria de dados representativos e valida√ß√£o ap√≥s o ajuste.'
                }));
                nodes.push(new Node(700, 300, 'DPO', 'training', 'Otimiza√ß√£o direta de prefer√™ncia', {
                    "Conceito": 'Converte feedback humano em um problema de classifica√ß√£o (resposta preferida vs n√£o preferida).',
                    "Vantagens": 'Elimina a necessidade de RL, reduz complexidade e instabilidade de treinamento„Äê540935989198974‚Ä†L50-L68„Äë.',
                    "Desempenho": 'Resultados compar√°veis ou melhores que RLHF em muitos benchmarks.',
                    "Uso": 'Alternativa eficiente para alinhar grandes modelos com feedback humano.',
                    "Observa√ß√£o": 'Requer pares de respostas anotadas e um modelo inicial robusto.'
                }));
                // Additional training node: Distillation
                nodes.push(new Node(900, 300, 'Destila√ß√£o', 'training', 'Teacher‚ÄëStudent', {
                    "Processo": 'Um modelo aluno menor aprende a imitar as distribui√ß√µes (soft labels) de um modelo professor grande.',
                    "Benef√≠cios": 'Compacta o modelo em ~40% mantendo 95‚Äì97% da performance„Äê994481608192740‚Ä†L88-L116„Äë.',
                    "Uso": 'Produ√ß√£o de Small Language Models (SLMs) e otimiza√ß√£o para dispositivos com restri√ß√£o de hardware.',
                    "Observa√ß√£o": 'Pode ser combinada com LoRA ou quantiza√ß√£o para ganhos adicionais.'
                }));
                // Prompt & RAG & Inference
                nodes.push(new Node(200, 450, 'Prompting', 'prompt', 'Engenharia de prompts', {
                    "Defini√ß√£o": 'Pr√°tica de criar e ajustar instru√ß√µes que guiam o modelo a gerar respostas relevantes e precisas.',
                    "T√©cnicas": 'Zero‚Äëshot, Few‚Äëshot, Chain‚Äëof‚ÄëThought (CoT), System/User prompts, In‚ÄëContext Learning.',
                    "Import√¢ncia": 'Um bom prompt reduz ambiguidades, melhora a qualidade da resposta e pode mitigar alucina√ß√µes.',
                    "Contexto": 'Limitado pela janela de contexto do modelo; exige equil√≠brio entre exemplos, instru√ß√µes e espa√ßo para resposta.',
                    "Boas pr√°ticas": 'Seja espec√≠fico, forne√ßa formato desejado, use exemplos representativos e considere dividir tarefas complexas.'
                }));
                nodes.push(new Node(400, 450, 'RAG', 'rag', 'Retrieval Augmented Generation', {
                    "Componentes": 'Recupera√ß√£o (vector search) + Gera√ß√£o (LLM).',
                    "Vantagens": 'Reduz alucina√ß√µes, fornece respostas fundamentadas e cit√°veis„Äê638945786534682‚Ä†L24-L117„Äë.',
                    "Requisitos": 'Embedding de documentos, banco vetorial, mecanismo de busca e m√≥dulo de reordena√ß√£o.',
                    "Funcionamento": 'Busca trechos relevantes, injeta como contexto no prompt e gera resposta combinando conhecimento do modelo e das fontes recuperadas.',
                    "Aplica√ß√µes": 'Assistentes empresariais, chatbots internos, FAQs e sistemas de suporte que necessitam de informa√ß√µes atualizadas.'
                }));
                nodes.push(new Node(600, 450, 'Infer√™ncia', 'inference', 'Gera√ß√£o de respostas', {
                    "Par√¢metros": 'Temperatura, Top‚Äëk, Top‚Äëp, Beam Width, comprimento m√°ximo.',
                    "Lat√™ncia": 'Varia conforme tamanho do modelo, hardware e contexto fornecido.',
                    "Alucina√ß√µes": 'Ocorr√™ncia de informa√ß√µes falsas ou inventadas; mitigadas por RAG e prompts claros„Äê379370150462339‚Ä†L90-L111„Äë.',
                    "Observa√ß√£o": 'Ajustar esses par√¢metros influencia criatividade, precis√£o e consist√™ncia das respostas.',
                    "Uso": 'Definir o estilo de gera√ß√£o (determin√≠stico vs criativo) em aplica√ß√µes de chat, c√≥digo, resumo e tradu√ß√£o.'
                }));
                nodes.push(new Node(800, 450, 'Embeddings', 'data', 'Vetoriza√ß√£o', {
                    "Defini√ß√£o": 'Representa√ß√£o de palavras, senten√ßas ou documentos como vetores num√©ricos em espa√ßo de alta dimens√£o.',
                    "Dimens√µes": 'Normalmente entre 768 e 4096, dependendo do modelo.',
                    "Uso": 'Permitem medir similaridade sem√¢ntica para busca, clustering e classifica√ß√£o.',
                    "Modelos": 'OpenAI Ada, HuggingFace E5/BGE, models espec√≠ficos para c√≥digo ou multimodal.',
                    "Considera√ß√£o": 'A qualidade da busca depende da qualidade dos embeddings e do banco vetorial utilizado.'
                }));
                // Connections
                // model -> training
                connections.push(new Connection(nodes[0], nodes[4], 'treina', 'animated'));
                connections.push(new Connection(nodes[1], nodes[4], 'treina', 'animated'));
                connections.push(new Connection(nodes[2], nodes[5], 'ajusta'));
                connections.push(new Connection(nodes[3], nodes[5], 'ajusta'));
                // training -> data
                connections.push(new Connection(nodes[4], nodes[7], 'usa'));
                connections.push(new Connection(nodes[5], nodes[7], 'produz'));
                connections.push(new Connection(nodes[6], nodes[7], 'produz'));
                connections.push(new Connection(nodes[8], nodes[7], 'reduz')); // Distillation -> Embeddings
                // training -> prompting/rag/inference
                connections.push(new Connection(nodes[4], nodes[9], 'informa'));
                connections.push(new Connection(nodes[5], nodes[10], 'ajusta'));
                connections.push(new Connection(nodes[6], nodes[10], 'ajusta'));
                connections.push(new Connection(nodes[8], nodes[10], 'compacta'));
                // rag/inference -> data
                connections.push(new Connection(nodes[10], nodes[11], 'gera', 'curved'));
                connections.push(new Connection(nodes[9], nodes[11], 'busca', 'curved'));
            }
            else if (currentView === 'models') {
                nodes.push(new Node(400, 100, 'Modelos Base', 'model', 'Modelos fundacionais')); 
                const modelList = [
                    ['GPT‚Äë4o', 'model', 'Multimodal'],
                    ['Claude 3', 'model', 'Opus/Sonnet/Haiku'],
                    ['Gemini Pro', 'model', '1M contexto'],
                    ['Llama 3', 'model', 'Open source'],
                    ['Mistral', 'model', 'Eficiente'],
                    ['Falcon', 'model', 'Multilingue'],
                    ['Phi‚Äë3', 'model', 'Pequeno e capaz'],
                    ['Qwen', 'model', 'Otimizado para chin√™s']
                ];
                modelList.forEach((m, idx) => {
                    const angle = (idx / modelList.length) * Math.PI * 2;
                    const x = 400 + Math.cos(angle) * 250;
                    const y = 300 + Math.sin(angle) * 150;
                    nodes.push(new Node(x, y, m[0], m[1], m[2]));
                });
                for (let i = 1; i < nodes.length; i++) {
                    connections.push(new Connection(nodes[0], nodes[i], '')); 
                }
            }
            else if (currentView === 'training') {
                nodes.push(new Node(200, 200, 'Dados', 'data', 'Dados de treinamento', {
                    "Fonte": 'Corpora extensos contendo texto, c√≥digo, imagens e √°udio provenientes da web, livros, artigos e dados licenciados.',
                    "Objetivo": 'Proporcionar diversidade lingu√≠stica e factual para que o modelo aprenda padr√µes gerais de linguagem e conhecimento de mundo.',
                    "Curadoria": 'Remove dados t√≥xicos, filtra informa√ß√µes sens√≠veis e equilibra distribui√ß√µes demogr√°ficas.',
                    "Sint√©ticos": 'Dados gerados artificialmente (self‚Äëinstruct, AI‚Äëgenerated) s√£o usados para ampliar cobertura e corrigir vieses.'
                }));
                nodes.push(new Node(400, 200, 'Pr√©‚Äëtreino', 'training', 'Pretraining', {
                    "Processo": 'O modelo √© exposto a sequ√™ncias massivas e aprende a prever o pr√≥ximo token (tarefa de modelagem de linguagem).',
                    "Resultado": 'Desenvolve um entendimento geral de sintaxe, sem√¢ntica e conhecimento enciclop√©dico.',
                    "T√©cnicas": 'M√°scaras, objetivos auto‚Äëregressivos ou auto‚Äëcodificadores, mistura de especialistas.',
                    "Custo": 'Alt√≠ssimo: requer GPUs/TPUs de ponta, semanas de processamento e grande consumo de energia.'
                }));
                nodes.push(new Node(600, 200, 'RLHF', 'training', 'Refor√ßo com feedback humano', {
                    "Fases": '1. Pr√©‚Äëtreinar o modelo base; 2. Treinar um modelo de recompensa a partir de compara√ß√µes humanas; 3. Ajustar o modelo via aprendizagem por refor√ßo para maximizar a recompensa„Äê468964752385088‚Ä†L60-L120„Äë.',
                    "Objetivo": 'Alinhar o comportamento do modelo a prefer√™ncias e valores humanos, reduzindo sa√≠das t√≥xicas e irrelevantes.',
                    "Funcionamento": 'Humanos avaliam pares de respostas; um modelo de recompensa aprende a pontuar; o modelo √© atualizado usando algoritmos como PPO.',
                    "Desafios": 'Exige ampla coleta de prefer√™ncias humanas, pode herdar vieses dos avaliadores e √© computacionalmente caro.',
                    "Uso": 'Fundamental em sistemas como ChatGPT e Claude para melhorar qualidade e seguran√ßa das respostas.'
                }));
                nodes.push(new Node(800, 200, 'DPO', 'training', 'Direct Preference Optimization', {
                    "Conceito": 'Transforma o feedback de prefer√™ncias humanas em um problema de classifica√ß√£o bin√°ria (preferido vs n√£o preferido) usando verossimilhan√ßa relativa.',
                    "Funcionamento": 'Dispensa a fase de RL: otimiza diretamente a probabilidade das respostas preferidas ser maior que a das n√£o preferidas„Äê540935989198974‚Ä†L50-L68„Äë.',
                    "Vantagens": 'Treinamento mais simples e est√°vel, dispensa amostragem e tuneamento de algoritmos de RL.',
                    "Desempenho": 'Alcan√ßa resultados compar√°veis ou superiores ao RLHF com menor custo computacional',
                    "Uso": 'Alternativa moderna para ajuste fino alinhado, adotada em pesquisas recentes.'
                }));
                nodes.push(new Node(300, 350, 'LoRA', 'training', 'Low‚ÄëRank Adaptation', {
                    "Como funciona": 'Insere matrizes de baixa classifica√ß√£o em camadas de aten√ß√£o e feedforward, enquanto mant√©m os pesos pr√©‚Äëtreinados congelados„Äê467744052411870‚Ä†L49-L63„Äë.',
                    "Benef√≠cios": 'Reduz os par√¢metros ajust√°veis em ordens de grandeza e economiza mem√≥ria GPU, permitindo ajustes r√°pidos em hardware modesto.',
                    "Aplica√ß√µes": 'Personalizar modelos de c√≥digo aberto (como Llama 2) para dom√≠nios espec√≠ficos ou tarefas de nicho sem treinar todos os par√¢metros.',
                    "Exemplo": 'Treinar apenas cabe√ßas de aten√ß√£o para aprender jarg√£o m√©dico sem alterar a rede inteira.'
                }));
                nodes.push(new Node(500, 350, 'QLoRA', 'training', 'Quantized LoRA', {
                    "Como funciona": 'Aplica LoRA em pesos quantizados a 4‚Äëbits, combinando compress√£o com baixo rank e, por vezes, destila√ß√£o para recuperar precis√£o.',
                    "Vantagens": 'Permite ajustar modelos gigantes (at√© 65B par√¢metros) em GPUs de consumidor √∫nicas, reduzindo consumo de mem√≥ria.',
                    "Aplica√ß√µes": 'Dom√≠nios especializados onde modelos extremamente grandes precisam ser adaptados com recursos limitados (ex. ci√™ncias da sa√∫de).',
                    "Observa√ß√£o": 'Equilibra custo e desempenho; quantiza√ß√£o agressiva pode degradar a qualidade se n√£o for calibrada.'
                }));
                nodes.push(new Node(700, 350, 'PEFT', 'training', 'Parameter Efficient Fine‚ÄëTuning', {
                    "O que √©": 'Categoria de t√©cnicas que atualizam apenas um subconjunto dos par√¢metros (adapters, prefix‚Äëtuning, IA3, LoRA).',
                    "Benef√≠cio": 'Diminui drasticamente o n√∫mero de pesos treinados, tornando o ajuste vi√°vel em hardware limitado.',
                    "Exemplos": 'IA3 (multiplica√ß√£o de vetores), Prefix‚ÄëTuning (prepende vetores trein√°veis), Adapters (camadas extras).',
                    "Uso": 'Popular em ambientes empresariais onde se deseja especializar modelos grandes sem incorrer em custos elevados.'
                }));
                nodes.push(new Node(900, 350, 'Destila√ß√£o', 'training', 'Teacher‚ÄëStudent', {
                    "Processo": 'Um modelo aluno menor √© treinado para aproximar as distribui√ß√µes de probabilidade (soft labels) produzidas por um modelo professor maior, preservando conhecimento.',
                    "Benef√≠cios": 'Reduz o tamanho do modelo em ~40% enquanto ret√©m 95‚Äì97% da performance do professor„Äê994481608192740‚Ä†L88-L116„Äë.',
                    "Aplica√ß√µes": 'Cria√ß√£o de Small Language Models (SLMs) port√°teis para dispositivos ou servi√ßos com baixa lat√™ncia.',
                    "Observa√ß√£o": 'Pode ser combinado com podas e quantiza√ß√£o para efici√™ncia extra.'
                }));
                nodes.push(new Node(500, 500, 'Modelo Final', 'model', 'Modelo ajustado', {
                    "Resultado": 'Modelo especializado para a tarefa alvo, pronto para infer√™ncia ou integra√ß√£o em sistemas.',
                    "Avalia√ß√£o": 'Valida√ß√£o em dados de teste, m√©tricas de precis√£o e robustez; ajustes finos de hiperpar√¢metros.',
                    "Desdobramentos": 'Pode ser usado diretamente, incorporado a pipelines RAG, disponibilizado via API ou iterativamente refinado.',
                    "Considera√ß√µes": 'Verificar vi√©s residual, desempenho fora de distribui√ß√£o e cumprimento de requisitos de seguran√ßa.'
                }));
                connections.push(new Connection(nodes[0], nodes[1], 'alimenta', 'animated'));
                connections.push(new Connection(nodes[1], nodes[2], 'refina'));
                connections.push(new Connection(nodes[1], nodes[3], 'alterna'));
                connections.push(new Connection(nodes[2], nodes[8], 'produz'));
                connections.push(new Connection(nodes[3], nodes[8], 'produz'));
                connections.push(new Connection(nodes[4], nodes[8], 'optimiza', 'curved'));
                connections.push(new Connection(nodes[5], nodes[8], 'optimiza', 'curved'));
                connections.push(new Connection(nodes[6], nodes[8], 'optimiza', 'curved'));
                connections.push(new Connection(nodes[7], nodes[8], 'compacta', 'curved'));
            }
            else if (currentView === 'rag') {
                nodes.push(new Node(200, 150, 'Documentos', 'data', 'Fontes externas', {
                    "Descri√ß√£o": 'Conjunto de documentos de onde as respostas ser√£o recuperadas (manuais, artigos, bases internas).',
                    "Formato": 'Texto, PDF, bases SQL, etc.',
                    "Import√¢ncia": 'Quanto maior e mais curado o corpus, melhor o contexto recuperado.'
                }));
                nodes.push(new Node(400, 150, 'Chunking', 'rag', 'Divis√£o de documentos', {
                    "Processo": 'Quebra os documentos em peda√ßos menores (par√°grafos ou senten√ßas).',
                    "Objetivo": 'Permitir que cada peda√ßo caiba na janela de contexto do modelo.',
                    "Cuidado": 'Preservar coer√™ncia e evitar cortar no meio de conceitos.'
                }));
                nodes.push(new Node(600, 150, 'Embeddings', 'data', 'Representa√ß√£o vetorial', {
                    "Defini√ß√£o": 'Vetores de n√∫meros que capturam o significado sem√¢ntico de cada chunk.',
                    "Modelos": 'Ada, E5, BGE, dentre outros.',
                    "Uso": 'Permite calcular similaridade sem√¢ntica para busca.'
                }));
                nodes.push(new Node(800, 150, 'Vector DB', 'rag', 'Banco vetorial', {
                    "Fun√ß√£o": 'Armazena embeddings e permite consultas de vizinhan√ßa.',
                    "Tipos": 'Pure (somente embeddings) ou integrado (embeddings + documentos)„Äê212488644229356‚Ä†L142-L175„Äë',
                    "Ferramentas": 'FAISS, Milvus, Pinecone, Weaviate'
                }));
                nodes.push(new Node(200, 350, 'Consulta', 'prompt', 'Consulta do usu√°rio', {
                    "O que √©": 'Pergunta ou comando para o sistema RAG.',
                    "Exemplo": '‚ÄúComo implementar LoRA em Llama?‚Äù',
                    "Dica": 'Use linguagem natural, pois a busca sem√¢ntica interpreta o significado.'
                }));
                nodes.push(new Node(400, 350, 'Busca', 'rag', 'Busca sem√¢ntica', {
                    "Processo": 'Calcula similaridade entre a consulta e cada embedding.',
                    "Top‚ÄëK": 'Seleciona os K peda√ßos mais relevantes.',
                    "Objetivo": 'Retornar o material mais √∫til para responder √† consulta.'
                }));
                nodes.push(new Node(600, 350, 'Rerank', 'rag', 'Reordenar resultados', {
                    "O que faz": 'Reavalia os trechos recuperados e os ordena por relev√¢ncia usando modelos de ranking.',
                    "Benef√≠cio": 'Ajuda a escolher chunks mais precisos, mesmo que n√£o sejam os mais pr√≥ximos semanticamente.',
                    "Ferramentas": 'Cross‚Äëencoders (re-ranking) ou modelos de similaridade refinados.'
                }));
                nodes.push(new Node(800, 350, 'Contexto', 'prompt', 'Constru√ß√£o de contexto', {
                    "Descri√ß√£o": 'Seleciona e concatena os chunks finalistas para inserir no prompt do LLM.',
                    "Limite": 'Precisa caber na janela de contexto do modelo.',
                    "Estrat√©gias": 'Filtrar redund√¢ncias, agrupar por t√≥pico.'
                }));
                nodes.push(new Node(500, 500, 'LLM', 'model', 'Modelo de linguagem', {
                    "Fun√ß√£o": 'Recebe a consulta original + contexto recuperado e gera a resposta final.',
                    "Benef√≠cio": 'Combina conhecimento geral do modelo com dados recentes ou propriet√°rios.',
                    "Observa√ß√£o": 'Os prompts devem referenciar as cita√ß√µes recuperadas para maior clareza.'
                }));
                nodes.push(new Node(700, 500, 'Resposta', 'inference', 'Sa√≠da final', {
                    "Composi√ß√£o": 'Texto gerado pelo LLM usando o contexto fornecido.',
                    "Verifica√ß√£o": 'Pode ser validada por modelos de verifica√ß√£o ou regras de neg√≥cio.',
                    "Uso": 'Enviado ao usu√°rio ou sistema que acionou a consulta.'
                }));
                connections.push(new Connection(nodes[0], nodes[1], 'divide', 'animated'));
                connections.push(new Connection(nodes[1], nodes[2], 'vetoriza'));
                connections.push(new Connection(nodes[2], nodes[3], 'armazenar'));
                connections.push(new Connection(nodes[5], nodes[6], 'ordena'));
                connections.push(new Connection(nodes[6], nodes[7], 'seleciona'));
                connections.push(new Connection(nodes[7], nodes[8], 'alimenta'));
                connections.push(new Connection(nodes[8], nodes[9], 'gera', 'animated'));
                connections.push(new Connection(nodes[3], nodes[5], 'consulta', 'curved'));
                connections.push(new Connection(nodes[4], nodes[5], 'busca', 'animated'));
                connections.push(new Connection(nodes[0], nodes[4], 'coleta'));  
            }
            else if (currentView === 'inference') {
                nodes.push(new Node(400, 100, 'Entrada', 'prompt', 'Entrada do usu√°rio', {
                    "Defini√ß√£o": 'O texto inicial fornecido ao modelo; no caso RAG inclui contexto recuperado.',
                    "Import√¢ncia": 'Define a tarefa e limita a gera√ß√£o de resposta.',
                    "Dica": 'Seja espec√≠fico e inclua todas as informa√ß√µes relevantes.'
                }));
                nodes.push(new Node(200, 250, 'Temperatura', 'inference', 'Controla criatividade', {
                    "Escala": 'Valor cont√≠nuo ‚â• 0; ao aproximar de 0, a distribui√ß√£o de probabilidade concentra‚Äëse na op√ß√£o mais prov√°vel; valores >1 achatam a distribui√ß√£o.',
                    "Efeito": 'Temperaturas baixas tornam a sa√≠da determin√≠stica e factual; temperaturas altas promovem criatividade e variabilidade.',
                    "Uso": '0.1‚Äì0.5 para tarefas factuais e an√°lises precisas; 0.7‚Äì1.2 para hist√≥rias criativas ou brainstorming.',
                    "Observa√ß√£o": 'Temperatura nula (0) equivale a escolher sempre o token de maior probabilidade, eliminando aleatoriedade.'
                }));
                nodes.push(new Node(400, 250, 'Top‚ÄëK', 'inference', 'Sele√ß√£o top‚ÄëK', {
                    "Defini√ß√£o": 'Mant√©m os K tokens mais prov√°veis em cada passo e zera as probabilidades dos demais antes da amostragem.',
                    "Impacto": 'Restringe a gera√ß√£o a um vocabul√°rio reduzido, diminuindo o risco de tokens raros e incoerentes.',
                    "Configura√ß√£o": 'K t√≠pico varia de 20 a 50; K=1 equivale a gera√ß√£o gulosa; K altos (>100) se aproximam da distribui√ß√£o completa.',
                    "Considera√ß√µes": 'Combinar com temperatura para controlar diversidade; valores muito baixos podem resultar em sa√≠das repetitivas.'
                }));
                nodes.push(new Node(600, 250, 'Top‚ÄëP', 'inference', 'Amostragem por n√∫cleo', {
                    "Nucleus Sampling": 'Seleciona o conjunto m√≠nimo de tokens cujo somat√≥rio cumulativo de probabilidade atinge P (0<P‚â§1).',
                    "Benef√≠cio": 'Adapta dinamicamente o tamanho do conjunto, combinando robustez do Top‚ÄëK com flexibilidade.',
                    "Configura√ß√£o": 'P entre 0.8 e 0.95 gera textos variados; valores baixos aumentam precis√£o mas reduzem criatividade.',
                    "Considera√ß√µes": 'Pode ser combinado com Top‚ÄëK para limitar o tamanho m√°ximo do n√∫cleo.',
                    "Exemplo": 'Com P=0.9, o modelo considera apenas os tokens mais prov√°veis cuja soma de probabilidades chega a 90%.'
                }));
                nodes.push(new Node(300, 400, 'Beam Search', 'inference', 'Busca em feixes', {
                    "Como funciona": 'Mant√©m v√°rias sequ√™ncias candidatas simultaneamente e expande as mais promissoras.',
                    "Benef√≠cio": 'Maior probabilidade de encontrar a melhor sequ√™ncia global',
                    "Custo": 'Mais lento e propenso a resultados repetitivos'
                }));
                nodes.push(new Node(500, 400, 'Greedy', 'inference', 'Escolha gulosa', {
                    "Princ√≠pio": 'Seleciona sempre o token mais prov√°vel em cada passo.',
                    "Vantagem": 'R√°pido e simples',
                    "Limita√ß√£o": 'Pode levar a sa√≠das sub√≥timas e repetitivas'
                }));
                nodes.push(new Node(400, 550, 'Sa√≠da', 'inference', 'Texto gerado', {
                    "Processo": 'Resultado final ap√≥s a aplica√ß√£o dos par√¢metros de amostragem e busca.',
                    "Variabilidade": 'Mudan√ßas nos par√¢metros produzem respostas diferentes',
                    "Aplica√ß√£o": 'Pode ser texto, c√≥digo, resumo, etc.'
                }));
                connections.push(new Connection(nodes[0], nodes[1], 'configura'));
                connections.push(new Connection(nodes[0], nodes[2], 'configura'));
                connections.push(new Connection(nodes[0], nodes[3], 'configura'));
                connections.push(new Connection(nodes[1], nodes[6], 'influencia', 'curved'));
                connections.push(new Connection(nodes[2], nodes[6], 'influencia'));
                connections.push(new Connection(nodes[3], nodes[6], 'influencia', 'curved'));
                connections.push(new Connection(nodes[4], nodes[6], 'estrat√©gia'));
                connections.push(new Connection(nodes[5], nodes[6], 'estrat√©gia'));
            }
            else if (currentView === 'prompting') {
                nodes.push(new Node(400, 100, 'Prompt Engineering', 'prompt', 'Engenharia de prompts', {
                    "Conceito": 'Disciplina que ensina a formular prompts claros, estruturados e eficientes para modelos de linguagem.',
                    "Objetivo": 'Garantir que o LLM compreenda a tarefa e produza respostas √∫teis.'
                }));
                nodes.push(new Node(200, 250, 'Zero‚ÄëShot', 'prompt', 'Instru√ß√µes sem exemplos', {
                    "O que √©": 'O modelo recebe apenas uma instru√ß√£o clara sobre a tarefa, sem exemplos de entrada‚Äësa√≠da. Ele utiliza o conhecimento adquirido durante o treinamento para inferir como responder.',
                    "Base te√≥rica": 'A abordagem apoia‚Äëse no treinamento por instru√ß√µes e no RLHF, que ensina os modelos a seguir comandos mesmo sem demonstra√ß√µes„Äê212554985576919‚Ä†L197-L204„Äë„Äê468964752385088‚Ä†L60-L120„Äë.',
                    "Aplica√ß√µes": 'Classifica√ß√£o, sumariza√ß√£o, tradu√ß√£o e tarefas gerais onde a instru√ß√£o √© suficiente.',
                    "Boas pr√°ticas": 'Formule perguntas diretas, especifique o formato da resposta e evite ambiguidade.',
                    "Limita√ß√µes": 'Desempenho inferior em tarefas complexas que exigem formato ou racioc√≠nio espec√≠fico; pode produzir respostas gen√©ricas.'
                }));
                nodes.push(new Node(400, 250, 'Few‚ÄëShot', 'prompt', 'Inclui exemplos no prompt', {
                    "O que √©": 'O prompt apresenta alguns pares de exemplo (entrada ‚Üí sa√≠da) para guiar o modelo.',
                    "T√©cnica": 'Aproveita o aprendizado em contexto: o modelo infere padr√µes a partir dos exemplos e aplica √† nova consulta„Äê608879525387675‚Ä†L200-L206„Äë.',
                    "Vantagem": 'Melhora tarefas que exigem formato espec√≠fico ou l√≥gica particular, como convers√£o de formatos ou c√≥digos.',
                    "Cuidados": 'Consome tokens da janela de contexto; exemplos mal escolhidos podem enviesar a resposta; a ordem dos exemplos influencia o resultado.',
                    "Dicas": 'Inclua exemplos variados e representativos, mantenha consist√™ncia no formato e limite‚Äëse a alguns exemplos para n√£o esgotar o contexto.'
                }));
                nodes.push(new Node(600, 250, 'Chain‚Äëof‚ÄëThought', 'prompt', 'Racioc√≠nio passo a passo', {
                    "O que √©": 'O prompt orienta o modelo a expor suas etapas de racioc√≠nio intermedi√°rio antes de dar a resposta final.',
                    "Benef√≠cios": 'Aumenta a acur√°cia em matem√°tica, l√≥gica e tarefas que exigem decomposi√ß√£o de problemas„Äê504803264572417‚Ä†L66-L77„Äë.',
                    "Exemplo": 'Para somar 37 + 48, pe√ßa ao modelo para detalhar cada soma parcial (\"37 + 40 = 77, 77 + 8 = 85\").',
                    "Orienta√ß√µes": 'Combine com few‚Äëshot fornecendo exemplos de racioc√≠nio passo a passo; delimite cada passo claramente.',
                    "Precau√ß√µes": 'Pode revelar pensamento interno desnecess√°rio e consumir mais tokens; nem sempre melhora tarefas simples; use apenas quando o racioc√≠nio √© realmente necess√°rio.'
                }));
                nodes.push(new Node(200, 400, 'System Prompt', 'prompt', 'Define comportamento', {
                    "Fun√ß√£o": 'Estabelece as instru√ß√µes base do modelo (personalidade, tom e restri√ß√µes) antes de qualquer intera√ß√£o com o usu√°rio.',
                    "Design": 'Inclui persona (educado, professor, programador), estilo de resposta (formal, conciso) e limites (n√£o responder sobre temas proibidos).',
                    "Uso": 'Utilizado por aplica√ß√µes para calibrar o comportamento; os usu√°rios finais geralmente n√£o o veem (ex.: ChatGPT usa um system prompt).',
                    "Contexto": 'Essencial em agentes aut√¥nomos e chatbots para garantir consist√™ncia, alinhamento e seguran√ßa.',
                    "Exemplos": '‚ÄúVoc√™ √© um assistente educado e conciso que responde em portugu√™s‚Äù, ‚ÄúSiga a documenta√ß√£o e n√£o invente c√≥digos.‚Äù'
                }));
                nodes.push(new Node(400, 400, 'User Prompt', 'prompt', 'Instru√ß√µes do usu√°rio', {
                    "Conte√∫do": 'Pergunta ou comando fornecido pelo usu√°rio final ao modelo.',
                    "Estrutura": 'Inclui contexto (quem, o qu√™, por qu√™), instru√ß√£o clara e limita√ß√µes (n√∫mero de itens, formato, linguagem).',
                    "Dicas": 'Use linguagem precisa, evite pronomes amb√≠guos, delimite o escopo e pe√ßa formatos espec√≠ficos (lista, tabela).',
                    "Exemplo": '‚ÄúListe as cinco melhores pr√°ticas de seguran√ßa em React em uma tabela com coluna de descri√ß√£o e benef√≠cio.‚Äù'
                }));
                nodes.push(new Node(600, 400, 'Janela de Contexto', 'prompt', 'Limite de tokens', {
                    "Defini√ß√£o": 'N√∫mero m√°ximo de tokens que o modelo pode processar entre entrada e sa√≠da somadas.',
                    "Import√¢ncia": 'Determina quantos exemplos, instru√ß√µes e contexto adicional podem ser utilizados; limita a mem√≥ria de curto prazo do modelo.',
                    "Tamanho": 'Depende do modelo: GPT‚Äë3.5 (4k, 16k), GPT‚Äë4 (8k, 32k), Claude (200k), Gemini Pro (at√© 1M) e SLMs (~4k).',
                    "Estrat√©gias": 'Dividir tarefas longas em partes, usar resumo progressivo, aplicar RAG para acessar informa√ß√µes externas, e remover detalhes sup√©rfluos.',
                    "Cuidado": 'Exceder a janela resulta em cortes autom√°ticos e perda de contexto, o que pode gerar respostas imprecisas.'
                }));
                nodes.push(new Node(400, 550, 'Resposta', 'inference', 'Texto gerado', {
                    "Processo": 'Sa√≠da produzida pelo modelo ap√≥s processar o prompt e aplicar par√¢metros de gera√ß√£o (temperatura, top‚ÄëK, etc.).',
                    "Qualidade": 'Varia conforme a clareza do prompt, a capacidade do modelo e a configura√ß√£o de infer√™ncia.',
                    "P√≥s‚Äëprocessamento": 'Pode incluir formata√ß√£o adicional, verifica√ß√£o de consist√™ncia ou uso de agentes externos para valida√ß√£o.'
                }));
                connections.push(new Connection(nodes[0], nodes[1], 'tipo'));
                connections.push(new Connection(nodes[0], nodes[2], 'tipo'));
                connections.push(new Connection(nodes[0], nodes[3], 'tipo'));
                connections.push(new Connection(nodes[4], nodes[7], 'define'));
                connections.push(new Connection(nodes[5], nodes[7], 'especifica'));
                connections.push(new Connection(nodes[6], nodes[7], 'limita'));
                connections.push(new Connection(nodes[3], nodes[7], 'melhora', 'animated'));
            }
            // Set highlight property based on search query
            nodes.forEach(node => {
                node.highlight = searchQuery && node.label.toLowerCase().includes(searchQuery.toLowerCase());
            });
        }
        // Filtering function
        function filterNodes(query) {
            searchQuery = query.trim();
            nodes.forEach(node => {
                node.highlight = searchQuery && node.label.toLowerCase().includes(searchQuery.toLowerCase());
            });
            draw();
        }
        // Show node details
        function showNodeDetails(node) {
            const infoContent = document.getElementById('infoContent');
            let detailsHtml = `<div class="info-content"><h3>${node.getIcon()} ${node.label}</h3><p>${node.description}</p>`;
            if (Object.keys(node.details).length > 0) {
                detailsHtml += '<ul>';
                for (const [key, value] of Object.entries(node.details)) {
                    detailsHtml += `<li><strong>${key}:</strong> ${value}</li>`;
                }
                detailsHtml += '</ul>';
            }
            detailsHtml += '</div>';
            // Category-specific content similar to previous implementation
            if (node.type === 'model') {
                detailsHtml += `<div class="info-content"><h3>üìö Caracter√≠sticas dos Modelos</h3><p>Modelos de funda√ß√£o s√£o treinados em vastos conjuntos de dados textuais para desenvolver capacidades lingu√≠sticas gerais.</p><ul><li><strong>Par√¢metros:</strong> Bilh√µes a trilh√µes de pesos neurais</li><li><strong>Contexto:</strong> 4k a 1M+ tokens</li><li><strong>Multimodal:</strong> Texto, imagem, √°udio, v√≠deo</li><li><strong>Aplica√ß√µes:</strong> Chat, c√≥digo, an√°lise, cria√ß√£o</li></ul></div>`;
            }
            else if (node.type === 'training') {
                detailsHtml += `<div class="info-content"><h3>üéì T√©cnicas de Treinamento</h3><p>O ajuste fino adapta modelos pr√©‚Äëtreinados para tarefas espec√≠ficas.</p><ul><li><strong>RLHF:</strong> Alinhar com prefer√™ncias humanas</li><li><strong>DPO:</strong> Otimiza√ß√£o direta e mais simples</li><li><strong>LoRA:</strong> Adapta√ß√£o de baixo rank</li><li><strong>QLoRA:</strong> LoRA com quantiza√ß√£o 4‚Äëbit</li><li><strong>Destila√ß√£o:</strong> Teacher‚Äëstudent para criar SLMs</li></ul></div>`;
            }
            else if (node.type === 'rag') {
                detailsHtml += `<div class="info-content"><h3>üîç RAG - Retrieval Augmented Generation</h3><p>Combina busca em documentos com gera√ß√£o de texto para respostas mais precisas.</p><ul><li><strong>Chunking:</strong> Divide documentos</li><li><strong>Embeddings:</strong> Vetoriza√ß√£o sem√¢ntica</li><li><strong>Vector DB:</strong> Armazenamento eficiente</li><li><strong>Reranking:</strong> Otimiza relev√¢ncia</li></ul></div>`;
            }
            else if (node.type === 'inference') {
                detailsHtml += `<div class="info-content"><h3>‚ö° Par√¢metros de Infer√™ncia</h3><p>Controlam como o modelo gera respostas.</p><ul><li><strong>Temperatura:</strong> Criatividade vs precis√£o</li><li><strong>Top‚ÄëK/Top‚ÄëP:</strong> Sele√ß√£o de candidatos</li><li><strong>Max Tokens:</strong> Comprimento m√°ximo</li><li><strong>Beam/Greedy:</strong> Estrat√©gias de busca</li></ul></div>`;
            }
            else if (node.type === 'prompt') {
                detailsHtml += `<div class="info-content"><h3>üí≠ Engenharia de Prompts</h3><p>A arte de formular instru√ß√µes eficazes para LLMs.</p><ul><li><strong>Zero‚Äëshot:</strong> Sem exemplos</li><li><strong>Few‚Äëshot:</strong> Com exemplos</li><li><strong>Chain‚Äëof‚ÄëThought:</strong> Racioc√≠nio passo a passo</li><li><strong>System Prompt:</strong> Define comportamento</li></ul></div>`;
            }
            document.getElementById('infoContent').innerHTML = detailsHtml;
        }
        // View management
        function showView(view, btn) {
            currentView = view;
            document.querySelectorAll('.btn').forEach(b => b.classList.remove('active'));
            if (btn) btn.classList.add('active');
            // Reset zoom/offset
            scale = 1;
            offsetX = 0;
            offsetY = 0;
            searchQuery = '';
            document.getElementById('searchInput').value = '';
            initializeNodes();
            draw();
            // update info panel with description
            const viewDescriptions = {
                'overview': 'Vis√£o geral do ecossistema de LLMs com principais componentes e fluxos.',
                'models': 'Detalhes dos principais modelos de linguagem dispon√≠veis.',
                'training': 'Pipeline de treinamento e t√©cnicas de ajuste fino.',
                'rag': 'Fluxo completo de Retrieval Augmented Generation.',
                'inference': 'Par√¢metros e estrat√©gias de gera√ß√£o de texto.',
                'prompting': 'T√©cnicas de engenharia de prompts.'
            };
            document.getElementById('infoContent').innerHTML = `<div class="info-content"><h3>üìä ${view.charAt(0).toUpperCase() + view.slice(1)}</h3><p>${viewDescriptions[view]}</p><p style="margin-top: 10px; color: #94A3B8;">Clique nos elementos para explorar detalhes espec√≠ficos.</p></div>`;
        }
        // Mouse events
        canvas.addEventListener('mousemove', (e) => {
            const rect = canvas.getBoundingClientRect();
            const mx = e.clientX - rect.left;
            const my = e.clientY - rect.top;
            if (isDragging) {
                offsetX += mx - dragStartX;
                offsetY += my - dragStartY;
                dragStartX = mx;
                dragStartY = my;
                draw();
                return;
            }
            let hovered = false;
            nodes.forEach(node => {
                node.hover = node.isHovered(mx, my);
                if (node.hover) {
                    hovered = true;
                    canvas.style.cursor = 'pointer';
                    showTooltip(e.clientX, e.clientY, node);
                }
            });
            if (!hovered) {
                canvas.style.cursor = isDragging ? 'grabbing' : 'grab';
                hideTooltip();
            }
            draw();
        });
        canvas.addEventListener('mousedown', (e) => {
            const rect = canvas.getBoundingClientRect();
            const mx = e.clientX - rect.left;
            const my = e.clientY - rect.top;
            let clickedNode = null;
            nodes.forEach(node => {
                if (node.isHovered(mx, my)) {
                    clickedNode = node;
                    node.selected = !node.selected;
                }
            });
            if (clickedNode) {
                showNodeDetails(clickedNode);
            } else {
                isDragging = true;
                dragStartX = mx;
                dragStartY = my;
                canvas.style.cursor = 'grabbing';
            }
            draw();
        });
        canvas.addEventListener('mouseup', () => {
            isDragging = false;
            canvas.style.cursor = 'grab';
        });
        canvas.addEventListener('mouseleave', () => {
            hideTooltip();
            isDragging = false;
        });
        // Tooltip functions
        function showTooltip(x, y, node) {
            let html = `<strong style="color: #60A5FA">${node.label}</strong><br>`;
            html += `<span style="color: #CBD5E1">${node.description}</span>`;
            tooltip.innerHTML = html;
            tooltip.style.left = x + 10 + 'px';
            tooltip.style.top = y - 30 + 'px';
            tooltip.style.display = 'block';
        }
        function hideTooltip() {
            tooltip.style.display = 'none';
        }
        // Zoom controls
        function zoomIn() {
            scale = Math.min(scale * 1.2, 3);
            draw();
        }
        function zoomOut() {
            scale = Math.max(scale / 1.2, 0.5);
            draw();
        }
        function resetZoom() {
            scale = 1;
            offsetX = 0;
            offsetY = 0;
            draw();
        }
        // Animation
        function animateFlow() {
            if (animationFrame) {
                cancelAnimationFrame(animationFrame);
                animationFrame = null;
                particles = [];
                draw();
                return;
            }
            connections.forEach(conn => {
                if (Math.random() > 0.7) {
                    particles.push(new Particle(conn.from.x, conn.from.y, conn.to.x, conn.to.y, 'rgba(59, 130, 246, 1)'));
                }
            });
            function animate() {
                particles = particles.filter(p => p.update());
                if (Math.random() > 0.95 && particles.length < 20) {
                    const conn = connections[Math.floor(Math.random() * connections.length)];
                    particles.push(new Particle(conn.from.x, conn.from.y, conn.to.x, conn.to.y, 'rgba(139, 92, 246, 1)'));
                }
                draw();
                animationFrame = requestAnimationFrame(animate);
            }
            animate();
        }
        // Draw
        function draw() {
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            // grid
            ctx.strokeStyle = 'rgba(148, 163, 184, 0.05)';
            ctx.lineWidth = 1;
            const gridSize = 50 * scale;
            for (let x = (offsetX % gridSize); x < canvas.width; x += gridSize) {
                ctx.beginPath();
                ctx.moveTo(x, 0);
                ctx.lineTo(x, canvas.height);
                ctx.stroke();
            }
            for (let y = (offsetY % gridSize); y < canvas.height; y += gridSize) {
                ctx.beginPath();
                ctx.moveTo(0, y);
                ctx.lineTo(canvas.width, y);
                ctx.stroke();
            }
            // connections
            connections.forEach(conn => conn.draw());
            // nodes
            nodes.forEach(node => node.draw());
            // particles
            particles.forEach(p => p.draw());
        }
        // Resize canvas
        function resizeCanvas() {
            const container = canvas.parentElement;
            canvas.width = container.clientWidth - 40;
            canvas.height = 600;
            draw();
        }
        window.addEventListener('resize', resizeCanvas);
        // Initialize
        resizeCanvas();
        initializeNodes();
        draw();
        document.addEventListener('keydown', (e) => {
            if (e.key === '+' || e.key === '=') zoomIn();
            if (e.key === '-' || e.key === '_') zoomOut();
            if (e.key === '0') resetZoom();
            if (e.key === ' ') {
                e.preventDefault();
                animateFlow();
            }
        });
    </script>
</body>
</html>